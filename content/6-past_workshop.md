---
title: Past Workshop 
nav: Previous Workshop  
---

# 1st Workshop on HRI4Wellbeing @ IEEE RO-MAN 2022

{% include figure.html img="huggable.jpg" alt="wellbeing-pic" caption="" width="95%" %}

Robots have found their way into society only for task-oriented goals, such as cleaning or cooking at home, entertaining at malls, and supporting workers in a job environment. Those robots can perform very restrictive and repetitive tasks without involving any human interaction. In recent years, there has been an increasing interest in companion robots that could support people for their entertainment or wellbeing, such as Amazon Astro (i.e., Alexa embedded into a wheel-robot) or the personal robot Jibo (i.e., developed by the MIT Media Lab to connect with people and being a robotic friend). The need to introduce companion robots in clinical (e.g., therapeutic centers, hospitals) and non-clinical (e.g., homes, work environments, malls) contexts have been boosted by the COVID-19 pandemic, where many people were forced to stay at home alone or with their relatives. This has caused many wellbeing issues, such as depression and anxiety, to mention only a few examples, and has resulted in a higher interest in assistive technology to alleviate the everyday burden. Socially Assistive Robots (SARs) are a promising venue to support people in their lives and help improve their wellbeing. However, due to the lack of large scale datasets obtained over longer periods of time SARs are very limited in their capabilities to continuously adapt to each user's needs and socio-emotionally connect with them. This often increases the risk of perceiving the robots as asocial leading to user disappointment and dissatisfaction, which are crucial in a domain that requires adaptation and socio-emotional behavior to increase robots’ social capabilities to promote wellbeing. 
{: style="text-align: justify"}

For example, consider a socially assistive robot placed in the university students' residential rooms. It can assist university students in their everyday life tasks and monitor their wellbeing during stressful periods of their uni life (e.g., mid-terms, finals). If the student is too stressed out or is close to burnout, the robot could perceive the emotional and mental state of the student - detecting the emotion, stress, and depression levels of the student - and adapt to the student’s needs, specifically it could respond empathically trying to support the student conversationally, and  promoting mindfulness sessions, or suggesting external support  (e.g., “I know that exams are really stressful, but you need to take some time for yourself, would you like to do a meditation session?”). In this situation, if a robot is not able to comfort the student properly (e.g., if the student is stressed out for university exams, the robot keeps reminding him/her about the deadlines), this leads to student’s frustration fueling the risk of perceiving the robot as asocial and reducing the student’s willingness to interact with it.
{: style="text-align: justify"}

### List of topics
Topics included in the workshop, but not limited to, are the following:
- Affective robotics for wellbeing
- Socially assistive robots for wellbeing
- Robotics assistant/companion/coach for wellbeing
- Robotic design for wellbeing
- User studies for wellbeing (both in lab and field)
- Adaptation and personalization for wellbeing applications 
- Machine learning for wellbeing
- Concept papers on the role of robots for wellbeing
- Methods to measure wellbeing
- Ethics, Privacy, and Data Security Considerations

# Objective 

The main objective of this workshop is to bring together a multidisciplinary group of researchers to identify and address key challenges for studying socio-emotionally adaptive robots for wellbeing and its relevant aspect for socially assistive robots in the lab and in the field. The workshop aims at (1) including the advances in affective computing and machine learning into social robotics context; (2) investigating the crucial topic of wellbeing  in clinical and non-clinical contexts during a post-pandemic era; and (3) advancing the field of social robotics in a situated context focusing on open challenges.
{: style="text-align: justify"}

#### 1. Adaptive and Socio-emotional Robot Behaviors to Promote Wellbeing 
Despite their popularity in the machine learning community, adaptation and emotional  capabilities have not been explored largely in robotic applications. For robotic agents, learning adaptive and socio-emotional behaviors raises new challenges due to the critical issues of their embodiment and their social interaction with humans. 
This workshop seeks to draw a research agenda that encompasses the directions for machine learning methods highlighted in the literature and help researchers in the field of robotics to identify priorities and challenges to address in their future work.
{: style="text-align: justify"}

#### 2. The Role of Socially Assistive Robots for Wellbeing 
Within the HRI community, a promising venue to assist people with special needs during their everyday life tasks is Socially Assistive Robotics (SAR). SARs have been explored mainly for home assistance for the elderly and therapeutic interventions for children with autism.  Past works have also focused on using socially assistive robots for wellbeing. However, the understanding of their role in context is still in its infancy. With this open challenge in mind, this workshop will focus on better highlighting (i) which are the different roles a socially assistive robot can assume into specific context (e.g., in-home, therapeutic centers) to promote wellbeing (e.g., companion/peer, assistant, coach) and (ii) how the user perception of the robot changes across the different roles.  
{: style="text-align: justify"}

#### 3. Opportunities and Challenges of Designing Robots to Promote Wellbeing 
The robotic applications are spreading out into our everyday lives, leading to a greater understanding that robotic progress influences the human physical and social environments. Nowadays, the robotic field is pivoting towards the wellbeing and healthcare of the present and future generations. In this context, one of the main opportunities and challenges is the reflection on the design of robots for promoting wellbeing, which will be one of the important highlights of our workshop.
{: style="text-align: justify"}

# Speaker


### Hae Won Park, MIT Media Lab
{% include figure.html img="haewon_profile.JPG" alt="haewon-pic" caption="" width="25%" %}
Hae Won Park is a Research Scientist at the Personal Robots Group. She is also a Principal Investigator for the Social Robot Companions for Aging Program, leading the long-term personalization of interactive AI systems in domains that help human flourishing. She oversees and closely works with students on many projects including early childhood education, healthcare, eldercare,  family interaction, and emotional wellness. Before, she was a PhD student at the Institute of Robotics and Intelligent Machines (IRIM) at Georgia Tech, where Hae Won was a member of the Human-Automation Systems (HumAnS) Laboratory advised by Prof. Ayanna Howard. While doing her PhD, Hae Won co-founded Zyrobotics, a spin-off from Georgia Tech that is licensing the three patents from her research. 
{: style="text-align: justify"}

---

### Maja Mataric, University of Southern California
{% include figure.html img="Maja.jpg" alt="maja-pic" caption="" width="25%" %}
Maja Matarić is a Chan Soon-Shiong distinguished professor of Computer Science, Neuroscience, and Pediatrics at the University of Southern California, founding director of the USC Robotics and Autonomous Systems Center (rasc.usc.edu), co-director of the USC Robotics Research Lab (robotics.usc.edu), past interim Vice President of Research (Jan 2020-Jul 2021), past Vice Dean for Research (Jul 2006-Dec 2019) and past President of the USC faculty and the Academic Senate (2005-06). She received her PhD in Computer Science and Artificial Intelligence from MIT in 1994, MS in Computer Science from MIT in 1990, and BS in Computer Science from the University of Kansas in 1987. She is a Fellow of the American Association for the Advancement of Science (AAAS), IEEE, AAAI, and ACM, and recipient of the US Presidential Award for Excellence in Science, Mathematics, and Engineering Mentoring (PAESMEM) from President Obama, and the Okawa Foundation, NSF Career, the MIT TR100 Innovation, the IEEE Robotics and Automation Society Early Career, the Anita Borg Institute Women of Vision Innovation, Viterbi School Service Award and Junior Research Awards, and is featured in the documentary movie "Me & Isaac Newton." She is an advisory editor of three major journals and has published extensively in various areas of robotics. Prof. Mataric' is actively involved in K-12 outreach, leading the USC Viterbi K-12 STEM Center and developing free curricular materials for elementary and middle-school robotics courses in order to engage student interest in science, technology, engineering, and math (STEM) topics. Her Interaction Lab's research into socially assistive robotics is aimed at endowing robots with the ability to help people reach their potential through individual assistance (for convalescence, rehabilitation, training, and education) and team cooperation (for habitat monitoring and emergency response). Research details are found at robotics.usc.edu/interaction.
{: style="text-align: justify"}

---

### Rafael A Calvo, Imperial College
{% include figure.html img="RafaPhoto.jpg" alt="rafael-pic" caption="" width="25%" %}
Rafael A. Calvo, PhD (2000) is Professor at Imperial College London focusing on the design of systems that support wellbeing in areas of mental health, medicine and education, and on the ethical challenges raised by new technologies. In 2015 Calvo was appointed a Future Fellow of the Australian Research Council to study the design of wellbeing-supportive technology.
{: style="text-align: justify"}


<p>&nbsp;</p>

# Invited Talks
The multidisciplinary nature of this workshop brings together the synergy of multiple areas, such as Psychology and Machine Learning.  For this reason, besides the keynote speakers, we invite two experts in the field of Psychology and Machine Learning to provide their perspectives via a short presentation (around 15 minutes):
{: style="text-align: justify"}

---

### Deirdre Logan, Boston Children's Hospital
{% include figure.html img="deirdrelogan.jpeg" alt="dl-pic" caption="" width="25%" %}
Deirdre Logan, Ph.D. ABPP, is a pediatric psychologist in the Department of Anesthesia at Boston Children’s Hospital (BCH) and associate professor of psychology, Department of Psychiatry, Harvard Medical School. Since 2008 she has served as Director of Psychology Services for the Division of Pain Medicine at BCH. She directs the postdoctoral fellowship training program in pediatric pain psychology and is a member of the ACGME pain fellow training committee at BCH. Dr. Logan received her PhD in Clinical Psychology at the University of Michigan and completed postdoctoral training in pediatric psychology at The Children’s Hospital of Philadelphia, where she subsequently served on faculty in the Pain Management Program, Department of Anesthesia. 
{: style="text-align: justify"}

---

### Ognjen (Oggi) Rudovic
{% include figure.html img="oggi.jpeg" alt="oggi-pic" caption="" width="25%" %}
Ognjen Rudovic received the PhD degree from Imperial College London, U.K., in 2014. He is currently a research affiliate with the Affective Computing Group, MIT Media Lab, developing models for personalized machine learning from human data. He worked on machine-learning and computer vision models for automated analysis of human facial behavior with Imperial College London. He was the recipient of the Marie Curie Fellowship and the prestigious European Fellowship for rising scientists. His work has been featured in Science Robotics, New Scientist, and the BBC radio.
{: style="text-align: justify"}

<!--Open floor discussion: This workshop seeks to address the open challenges reported above (RC1 - RC3) with the contributed papers and the invited speaker presentations. During an open floor discussion, we will address those challenges and discuss possible solutions. Those challenges are provisional, and will change according to the keynote speakers’ talks and the paper submissions. 
We will divide the audience into three groups (breakout rooms in case of virtual or hybrid conference) that will be assigned to one of the research challenges delivered in the keynote speaker’s talks. The keynote speaker will also join their own topic group (provisional to their availability). At the end of the group discussion, we will rejoin the main workshop session, and each group will present their discussion’s outcomes. Also the attendees who will be present in-person will be assigned to a group team. For the sake of simplicity, we will create in-person groups, and online groups. However, the final main discussion will include both in-person and virtual attendees.
Workshop proceedings: We will include the workshop papers into the Workshop Proceedings collection available on arXiv. The papers could be 2-4 pages for short contributions and 6-8 pages for long paper contributions. Authors should use the RO-MAN template (http://www.smile.unina.it/ro-man2022/call-for-papers/) for the submission. Authors will be invited to present their accepted papers in a 15 minutes oral presentation during this workshop.
Special Issue: We want to publish a Special Issue containing contributions from workshop participants as well as other researchers working on related works to collect the knowledge and insights gained during the workshop. We are currently preparing a Special Issue proposal to be submitted to the International Journal of Social robotics. -->

# Program


##### All times are in Central European Time (CET).


| Time       | &nbsp; Program                 | 
| :---------- | :----------------------- | 
| 9:15       | &nbsp; Openings                | 
| 9:30       | &nbsp; Keynote Talk: Rafael A Calvo, Imperial College      | 
| 10:30      | &nbsp; Break                   | 
| 11:00      | &nbsp; Paper Presentation      |
|            | &nbsp; * "Loneliness in daily-life, could agents & robots help and how? Presentation and first elements of validation of the LAAM or Life-companion Agent Acceptance Model", Brice Pablo Diesbach, Jean-Philippe Galan and Michele Grimaldi |
|            | &nbsp; * "Explorative Study on Human Intuitive Responses to Observing Expressive Robot Behavior", Marieke van Otterdijk, Diana Saplacan, Bruno Laeng and Jim Torresen |
|            | &nbsp; * "Adaptive Robot-Assisted Autism Intervention for Children with ASD", Anara Sandygulova, Aida Amirova, Aida Zhanatkyzy, Zhansaule Telisheva and Nazerke Rakhymbayeva |
|            | &nbsp; * "Towards social embodied cobots: The integration of an industrial cobot with a social virtual agent", Matteo Lavit Nicora, Sebastian Beyrodt, Dimitra Tsovaltzi, Fabrizio Nunnari, Patrick Gebhard and Matteo Malosio |  
| 12:00      | &nbsp; Invited Talk: Ognjen (Oggi) Rudovic          | 
| 12:45      | &nbsp; Lunch            | 
| 14:15      | &nbsp; Invited Talk: Deirdre Logan, Boston Children's Hospital                 | 
| 14:45      | &nbsp; Paper Presentation |
|            | &nbsp; * "Design of child-robot interactions for comfort and distraction from post-operative pain and distress", Oriana Ferrari, Feiran Zhang, Jules van Gurp, Ayrton Braam, Frank Broz and Emilia Barakova |
|            | &nbsp; * "A Social Robot for Emotion Recognition and Burden Levels Assessment for Informal Caregivers", Samuel Millan Norman and Carolina Fuentes|
|            | &nbsp; * "Online Learners’ Cognitive-Affective States Awareness to support Wellbeing and Self-Regulation Skills", Marie-Luce Bourguet, Jacqueline Urakami and Gentiane Venture |  
|            | &nbsp; * "Can Robots Help in the Evaluation of Mental Wellbeing in Children? An Empirical Study", Nida Itrat Abbasi, Micol Spitale, Joanna Anderson, Tamsin Ford, Peter B. Jones and Hatice Gunes |
| 15:45      | &nbsp; Break |
| 16:00      | &nbsp; Keynote Talk:  Maja Mataric, University of Southern California | 
| 16:45      | &nbsp; Break                 | 
| 17:00      | &nbsp; Keynote Talk: Hae Won Park, MIT Media Lab          | 
| 17:45      | &nbsp; Closing           | 

# Organizers



### [Micol Spitale](https://micolspitale.com/)
{% include figure.html img="miafoto.jpg" alt="micole-pic" caption="" width="25%" %}
Postdoc at Affective Intelligence & Robotics (AFAR) Lab\
Department of Computer Science and Technology, University of Cambridge\
15 JJ Thomson Ave, Cambridge CB3 0FD, UK\
ms2871@cam.ac.uk

Micol Spitale is currently a PostDoc at the Affective Intelligence & Robotics Laboratory (AFAR Lab), Department of Computer Science & Technology of the University of Cambridge, under the supervision of professor Hatice Gunes. Her research focuses on developing a Socio-emotionally Adaptive Robotic (ARoEQ) platform that can foster wellbeing through coaching and psychologically-proven interventions. She has just finalised her Ph.D. (end of October 2021) in Information Technology (Computer Science and Engineering Area) affiliated with IBM Italy and co-funded by EIT Digital (started in November 2018), I3Lab,  Department of Electronics, Information, and Bioengineering at Politecnico di Milano. She has worked as a researcher assistant for six months on different research projects, such as social robots to convey emotions and multisensory rooms for children with neurodevelopmental disorders. Then, she won a Ph.D. fellowship, and she started her Ph.D. on “Conversational Technologies for Children with Cognitive Disabilities”. During her second year of Ph.D., she spent six months at the University of Southern California (USC) in the Interaction Lab. She explored the use of robots to support children with cognitive disabilities. Finally, her doctoral thesis focuses on applying conversational Socially Assistive Robots to assess and train the linguistic skills of children with language impairments.
{: style="text-align: justify"}

---

### [Sooyeon Jeong](https://www.sooyeonjeong.com/)
{% include figure.html img="SooyeonJeong.jpg" alt="sooyeon-pic" caption="" width="25%" %}
Postdoctoral Fellow at Center for Behavioral Intervention Technologies\
Feinberg School of Medicine\
Northwestern University\
750 N. Lake Shore Drive, 10th Floor, Chicago, IL, USA\
sooyeon.jeong@northwestern.edu

Sooyeon Jeong is a NRSA Postdoctoral Fellow at the Center for Behavioral Intervention Technologies at the Feinberg School of Medicine in Northwestern University. Her research focuses on designing and deploying interactive agents that can improve people's lives by providing personalized support based on each user's needs, traits and behaviors. She deploys these agents "in-the-wild" to evaluate how they build relationships/rapport with people over time and improve their wellbeing, health and learning. Sooyeon received the Best Paper Award at the RO-MAN conference in 2020, and her research has been featured in popular press outlets, including in the New York Times, the Wired Magazine, CNN International, etc. She received her B.S. and M.Eng in Electrical Engineering and Computer Science at MIT and M.S. and Ph.D in Media Arts and Science from MIT Media Lab. 
{: style="text-align: justify"}

---

### [Emilia Barakova](https://www.tue.nl/en/research/researchers/emilia-barakova/)
{% include figure.html img="EmiliaWEB.jpg" alt="emilia-pic" caption="" width="25%" %}
Assistant Professor of Socially Intelligent Systems\
Department of Industrial Design\
Atlas 4.122, 5612 AZ Eindhoven, Netherlands\
e.i.barakova@tue.nl

Emilia I. Barakova received a Ph.D. degree in mathematics and physics from Groningen University, Groningen, The Netherlands, in 1999 and holds a Masters' degree from Technical University Sofia, Bulgaria. She is currently with the Department of Industrial Design, Eindhoven University of Technology, Eindhoven, The Netherlands, and leads the Social robotics Lab of the Eindhoven University of Technology. She has held research positions at RIKEN Brain Science Institute (Japan), GMD-Japan Research Laboratory (Japan), Groningen University (The Netherlands), and the Bulgarian Academy of Science (Bulgaria). She is an associate editor of the International Journal of Social Robotics and Editor of Personal and Ubiquitous Computing and has organized several IEEE and ACM conferences. She has expertise in social robotics, AI and robotics, modeling emotions and social behavior, and human-centered interaction design.
{: style="text-align: justify"}

---

### [Hatice Gunes](https://www.cl.cam.ac.uk/~hg410/)
{% include figure.html img="Hatice.jpg" alt="hatice-pic" caption="" width="25%" %}
Professor of Affective Intelligence & Robotics\
Department of Computer Science and Technology, University of Cambridge\
William Gates Building, 15 JJ Thomson Avenue, Cambridge, CB3 0FD, UK\
Hatice.Gunes@cl.cam.ac.uk

Hatice Gunes is a Professor of Affective Intelligence and Robotics (AFAR) and the Head of the AFAR Lab at the University of Cambridge's Department of Computer Science and Technology. Her expertise is in the areas of affective computing and social signal processing cross-fertilising research in multimodal interaction, computer vision, signal processing, machine learning and social robotics. She has published over 125 papers in these areas (H-index=34, citations > 6,000),  with  most  recent  works  on lifelong learning for facial expression recognition, fairness and affective robotics; and longitudinal HRI for wellbeing. She was one of the Guest Editors of the 2021 IEEE Transactions on Affective Computing Special Issue on Automated Perception of Human Affect from Longitudinal Behavioral Data. Other research highlights  include  RSJ/KROS  Distinguished  Interdisciplinary Research Award Finalist at IEEE RO-MAN’21, Distinguished PC Award at IJCAI’21, Best Paper Award Finalist at IEEE RO-MAN’20, Finalist for the 2018 Frontiers Spotlight Award, Outstanding Paper Award at IEEE FG’11, and Best Demo Award at IEEE ACII’09. Prof Gunes is the former President of the Association for the Advancement of Affective Computing (AAAC), and was the General Co-Chair of ACII’19, and the Program Co-Chair of ACM/IEEE HRI’20 and IEEE FG’17. She was a member of the Human-Robot Interaction Steering Committee (2018-2021) and was the Chair of the Steering Board of IEEE Transactions on Affective Computing (2017-2019). In 2019 she was awarded the prestigious EPSRC Fellowship as a personal grant to investigate adaptive robotic emotional intelligence for wellbeing and was named a Faculty Fellow of the Alan Turing Institute– UK’s national centre for data science and artificial intelligence (2019-2021). Prof Gunes is a Senior Member of the IEEE and a member of the AAAC.
{: style="text-align: justify"}
